# Development Gap Analysis - October 1, 2025

## Overview

This document identifies gaps between the current socket-based pipeline implementation and the best practices outlined in `DEV_PLAN_2025_1001.md`. The analysis focuses on what's missing to enable scientific measurement, optimization, and production-ready streaming.

---

## Gap 1: Instrumentation & Monitoring (CRITICAL)

### Status: Phase 1 - High Priority

**Current State:**
- Minimal logging in `socket_producer.py`: `bytes_received`, `packets_received`, `batches_generated`
- No real-time pipeline health metrics
- No queue occupancy tracking
- No throughput rate measurement

**Missing Capabilities:**

#### 1.1 Queue Depth Monitoring
**Location:** `utils/queue.py`, pipeline execution loop

**What's Missing:**
```python
# Need real-time Q1 monitoring with target >80% utilization
def monitor_queue_health(q1_manager, interval=0.1):
    """Log queue depth over time to detect starvation."""
    depth = q1_manager.size()
    max_depth = q1_manager.num_shards * q1_manager.maxsize_per_shard
    utilization = depth / max_depth

    if utilization < 0.3:
        logging.warning(f"Potential data starvation: Q1 at {utilization:.1%}")
```

**Files to Modify:**
- `peaknet_pipeline_ray/core/peaknet_pipeline.py` (main execution loop)
- `peaknet_pipeline_ray/utils/queue.py` (add queue monitoring methods)

#### 1.2 Throughput Measurement
**Location:** `coordinator.py`, producer/consumer actors

**What's Missing:**
- Producer throughput (samples/sec)
- Consumer throughput (samples/sec)
- Throughput ratio calculation
- Real-time rate comparison logging

**Implementation Needed:**
```python
class ThroughputMonitor:
    """Track and compare producer vs consumer rates."""
    def __init__(self):
        self.producer_samples = 0
        self.consumer_samples = 0
        self.start_time = time.time()

    def get_rates(self):
        elapsed = time.time() - self.start_time
        producer_rate = self.producer_samples / elapsed
        consumer_rate = self.consumer_samples / elapsed
        return producer_rate, consumer_rate, producer_rate / consumer_rate
```

**Files to Create/Modify:**
- New: `peaknet_pipeline_ray/monitoring/throughput_monitor.py`
- Modify: `core/coordinator.py` (integrate throughput tracking)

#### 1.3 GPU Utilization Monitoring
**Location:** Pipeline actor

**What's Missing:**
- GPU utilization percentage over time
- Correlation with queue depth
- Detection of GPU idle periods

**Integration Points:**
- `peaknet_ray_pipeline_actor.py`: Add nvidia-smi polling or NVML integration
- Pipeline loop: Log GPU utilization every N batches

#### 1.4 Pipeline Stage Timing Breakdowns
**Location:** `peaknet_ray_pipeline_actor.py`

**What's Missing:**
```python
# Need detailed timing for each stage
timings = {
    'h2d_transfer': [],      # Host to device
    'kernel_execution': [],  # GPU compute
    'd2h_transfer': [],      # Device to host
    'parsing_overhead': [],  # HDF5/NumPy parsing (socket mode)
}
```

**Files to Modify:**
- `core/peaknet_ray_pipeline_actor.py` (add CUDA event timing)
- Pipeline config: Add `enable_detailed_timing` flag

---

## Gap 2: Backpressure Mechanism (CRITICAL)

### Status: Direction 2 - High Priority

**Current State:**
- Basic queue fullness check in `socket_producer.py:346-349`
- Simple 10ms retry on queue full
- No Ray actor concurrency limits
- No proactive throttling

**Problem:**
When producer rate > consumer rate, Ray object store will spill to disk (massive performance degradation). Current implementation has no protection against this.

**Missing Capabilities:**

#### 2.1 Ray Actor Concurrency Limits
**Location:** `socket_producer.py`, producer actor definition

**What's Missing:**
```python
# Current: No concurrency control
@ray.remote
class SocketProducer:
    ...

# Needed: Ray-native backpressure
@ray.remote(
    max_concurrency=1,           # Process one batch at a time
    max_pending_calls=100        # Limit queue of pending tasks
)
class SocketProducer:
    ...
```

**Files to Modify:**
- `core/socket_producer.py:58` (add Ray actor options)
- Config schema: Add `producer_max_concurrency` parameter

#### 2.2 Smart Queue-Based Throttling
**Location:** Producer streaming loop

**What's Missing:**
```python
# Current: Fixed 10ms retry
if not success:
    time.sleep(0.01)

# Needed: Adaptive backpressure based on queue depth
def should_throttle(queue_manager, threshold=0.9):
    """Check if producer should slow down."""
    utilization = queue_manager.size() / queue_manager.max_capacity
    return utilization > threshold  # Throttle at 90% full

# In producer loop:
if should_throttle(queue_manager):
    throttle_delay = calculate_adaptive_delay(queue_utilization)
    time.sleep(throttle_delay)
```

**Files to Modify:**
- `core/socket_producer.py` (add throttling logic in `stream_raw_bytes_to_queue`)
- Config: Add `backpressure_threshold` (default: 0.9)

#### 2.3 Object Store Spill Prevention
**Location:** Pipeline initialization, monitoring

**What's Missing:**
- Object store size configuration at Ray init
- Spill event monitoring
- Early warning system before spill occurs

**Implementation Needed:**
```python
# At Ray initialization
ray.init(object_store_memory=10 * 1024**3)  # 10GB

# During execution
def check_object_store_pressure():
    """Monitor object store and warn before spill."""
    stats = ray.cluster_resources()
    # Check object_store_memory usage
    if usage > 0.8:  # 80% threshold
        logging.warning("Object store approaching capacity - expect spill")
```

**Files to Modify:**
- `pipeline.py` (Ray init configuration)
- `core/coordinator.py` (add object store monitoring)

---

## Gap 3: Object Store Management (MEDIUM PRIORITY)

### Status: Direction 2 - Not Configured

**Current State:**
- Uses default Ray object store size (system memory / 2)
- No explicit configuration
- No capacity planning

**Missing Capabilities:**

#### 3.1 Object Store Sizing
**Location:** Ray initialization in pipeline entry point

**What's Missing:**
```yaml
# Config file should include:
system:
  object_store_memory: 10737418240  # 10GB in bytes
  # OR percentage-based:
  object_store_memory_fraction: 0.3  # 30% of system memory
```

**Files to Modify:**
- `config/schemas.py` (add object_store configuration)
- `pipeline.py` (use config for Ray init)

#### 3.2 Queue Sizing Strategy
**Location:** Pipeline configuration

**Current:**
```yaml
runtime:
  queue_num_shards: 8
  queue_maxsize_per_shard: 1600  # Total: 12,800 items
```

**Missing:** Scientific basis for these numbers

**Need to Add:**
- Memory budget calculation (queue capacity * item size < object store size)
- Burst handling capacity (how many batches can queue during network spike)
- Steady-state sizing (producer rate * acceptable latency)

**Documentation Needed:**
- Sizing guide in config comments
- Calculation formula based on workload

#### 3.3 Spill Monitoring
**Location:** Monitoring system

**What's Missing:**
```python
# Monitor and log spill events
def check_spill_status():
    """Check if Ray is spilling to disk."""
    # Use: ray memory --stats
    # Or: ray.cluster_resources()
    # Log warnings when spill detected
```

**Files to Create:**
- New: `monitoring/object_store_monitor.py`

---

## Gap 4: Producer-Consumer Ratio Analysis (HIGH PRIORITY)

### Status: Direction 1 - No Infrastructure

**Current State:**
- No throughput comparison capability
- No rate measurement infrastructure
- Cannot determine optimal scaling ratios

**Missing Capabilities:**

#### 4.1 Rate Measurement Infrastructure
**Location:** Producer and consumer actors

**What's Missing:**
```python
class ProducerMetrics:
    """Track producer-side metrics."""
    samples_produced: int = 0
    start_time: float = 0.0

    def get_rate(self):
        return self.samples_produced / (time.time() - self.start_time)

class ConsumerMetrics:
    """Track consumer-side metrics."""
    samples_consumed: int = 0
    start_time: float = 0.0

    def get_rate(self):
        return self.samples_consumed / (time.time() - self.start_time)
```

**Files to Create/Modify:**
- New: `monitoring/metrics.py` (centralized metrics collection)
- Modify: `socket_producer.py`, `peaknet_ray_pipeline_actor.py` (emit metrics)

#### 4.2 Real-Time Rate Comparison
**Location:** Coordinator or dedicated monitor

**What's Missing:**
```python
def analyze_rate_ratio(producer_rate, consumer_rate, target_ratio=1.15):
    """
    Analyze producer/consumer rate ratio.

    Target: Producer 10-20% faster than consumer (keeps GPUs fed)
    """
    actual_ratio = producer_rate / consumer_rate

    if actual_ratio < 1.0:
        return "PRODUCER_BOTTLENECK", "Producer too slow - GPUs starving"
    elif actual_ratio > 1.5:
        return "CONSUMER_BOTTLENECK", "Consumer too slow - queue spill risk"
    else:
        return "HEALTHY", f"Rate ratio {actual_ratio:.2f} within target range"
```

**Files to Create:**
- New: `monitoring/rate_analyzer.py`
- Integration: Log analysis results every N seconds

#### 4.3 Alerting System
**Location:** Monitoring loop

**What's Missing:**
- Warnings when rates diverge significantly
- Recommendations for scaling (add/remove producers/consumers)
- Automatic adjustment suggestions

---

## Gap 5: Configuration Schema Gaps (MEDIUM PRIORITY)

### Status: Missing operational parameters

**Current Config:**
```yaml
runtime:
  queue_num_shards: 8
  queue_maxsize_per_shard: 1600
  max_empty_polls: 500
  poll_timeout: 0.001
```

**Missing Parameters:**

```yaml
# Backpressure configuration
backpressure:
  enabled: true
  queue_threshold: 0.9          # Throttle producers at 90% Q1 capacity
  producer_max_concurrency: 1   # Ray actor concurrency limit
  producer_max_pending: 100     # Ray pending calls limit
  adaptive_delay: true          # Use adaptive throttling delay

# Object store configuration
object_store:
  memory_bytes: 10737418240     # 10GB explicit sizing
  spill_warning_threshold: 0.8  # Warn at 80% usage

# Monitoring configuration
monitoring:
  enabled: true
  metrics_log_interval: 10      # Log metrics every 10 batches
  throughput_window: 30         # Calculate rates over 30s window
  queue_depth_logging: true     # Log Q1 depth regularly
  gpu_utilization_tracking: true

# Performance targets
performance:
  target_producer_consumer_ratio: 1.15  # Producer 15% faster
  min_queue_utilization: 0.8            # Keep Q1 >80% full
  max_gpu_idle_time_ms: 5.0             # Alert if GPU idle >5ms
```

**Files to Modify:**
- `config/schemas.py` (add new config dataclasses)
- Example configs (update with new parameters)

---

## Gap 6: Experimental Infrastructure (MEDIUM PRIORITY)

### Status: Direction 1 - No Tools for Systematic Testing

**Current State:**
- Manual profiling with nsys
- No automated parameter sweep capability
- No comparative benchmarking tools

**Missing Capabilities:**

#### 6.1 Batch Size Sweep Tools
**What's Missing:**
```bash
# Need automated sweep tool
peaknet-sweep --config base.yaml --sweep-param runtime.batch_size --values 1,2,4,8,16,32
```

**Files to Create:**
- New: `tools/parameter_sweep.py`
- Script to automate experiments from DEV_PLAN Phase 2

#### 6.2 Profiling Automation
**What's Missing:**
- Automatic nsys report generation
- Metrics extraction from profiling data
- Comparison reports (random vs socket mode)

**Files to Create:**
- New: `tools/profile_analyzer.py`
- Parse nsys output, extract key metrics

#### 6.3 Results Tracking
**What's Missing:**
- Database/CSV of experiment results
- Trend analysis across runs
- Optimal configuration discovery

---

## Gap 7: Documentation & Best Practices (LOW PRIORITY)

### Status: Missing operational guides

**Current State:**
- Code comments exist
- No tuning guide
- No troubleshooting runbook

**Missing Documentation:**

1. **Tuning Guide** (`docs/TUNING_GUIDE.md`)
   - How to size object store
   - Queue capacity calculations
   - Producer/consumer ratio guidelines

2. **Troubleshooting Runbook** (`docs/TROUBLESHOOTING.md`)
   - Diagnosing data starvation
   - Fixing object store spill
   - Identifying bottlenecks

3. **Monitoring Guide** (`docs/MONITORING.md`)
   - Key metrics to watch
   - Healthy vs unhealthy patterns
   - Alert thresholds

---

## Summary: Implementation Priority

### Critical Path (Enables Investigation)

**Week 1:**
1. **Queue depth monitoring** (Gap 1.1)
   - Modify: `utils/queue.py`, `core/peaknet_pipeline.py`
   - Add real-time Q1 utilization logging

2. **Throughput measurement** (Gap 4.1, 4.2)
   - Create: `monitoring/throughput_monitor.py`
   - Integrate in producer/consumer actors

3. **Basic backpressure** (Gap 2.1, 2.2)
   - Modify: `socket_producer.py` (add Ray actor limits)
   - Add queue-based throttling logic

**Week 2:**
4. **Pipeline stage timing** (Gap 1.4)
   - Modify: `peaknet_ray_pipeline_actor.py`
   - Add H2D/Compute/D2H breakdowns

5. **Object store monitoring** (Gap 3.3)
   - Create: `monitoring/object_store_monitor.py`
   - Integrate spill detection

6. **Configuration schema** (Gap 5)
   - Update: `config/schemas.py`
   - Add monitoring/backpressure parameters

### Secondary (Optimization)

**Week 3-4:**
7. GPU utilization tracking (Gap 1.3)
8. Experimental tools (Gap 6)
9. Documentation (Gap 7)

---

## Files Requiring Modification

### High Priority
- `peaknet_pipeline_ray/utils/queue.py` - Add monitoring methods
- `peaknet_pipeline_ray/core/socket_producer.py` - Add backpressure
- `peaknet_pipeline_ray/core/peaknet_pipeline.py` - Integrate monitoring
- `peaknet_pipeline_ray/core/coordinator.py` - Add metrics tracking
- `peaknet_pipeline_ray/config/schemas.py` - Extend configuration

### New Files Needed
- `peaknet_pipeline_ray/monitoring/throughput_monitor.py`
- `peaknet_pipeline_ray/monitoring/object_store_monitor.py`
- `peaknet_pipeline_ray/monitoring/metrics.py`
- `peaknet_pipeline_ray/monitoring/rate_analyzer.py`

### Configuration Updates
- `examples/configs/peaknet-socket.yaml` - Add monitoring/backpressure params

---

## Success Criteria

Implementation is complete when:

1. **Observability**: Can answer "Is GPU starving?" with data
2. **Metrics**: Know producer vs consumer rates in real-time
3. **Safety**: Pipeline never spills to disk unintentionally
4. **Actionability**: Clear recommendations when performance degrades
5. **Reproducibility**: Can run systematic experiments from DEV_PLAN

---

## References

- **Parent Document**: `DEV_PLAN_2025_1001.md`
- **Investigation Plan**: `SOCKET_DATA_STARVATION_INVESTIGATION.md`
- **Ray Best Practices**: `/sdf/data/lcls/ds/prj/prjcwang31/results/learn-ray/PATTERNS.md`
